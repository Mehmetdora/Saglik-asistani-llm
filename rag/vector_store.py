import chromadb
from chromadb.config import Settings
from pathlib import Path
import json
from typing import List, Dict
from .embedder import TurkishEmbedder


class HealthVectorStore:
    """SaÄŸlÄ±k asistanÄ± iÃ§in vector database"""

    def __init__(self, db_path="data/chroma_db"):
        self.db_path = Path(db_path)
        self.db_path.mkdir(parents=True, exist_ok=True)

        print(f"ğŸ’¾ ChromaDB baÅŸlatÄ±lÄ±yor: {self.db_path}")

        # ChromaDB client
        self.client = chromadb.PersistentClient(path=str(self.db_path))

        # Collection (tablo gibi dÃ¼ÅŸÃ¼n)
        self.collection_name = "diseases"

        # Embedder
        self.embedder = TurkishEmbedder()

        print(f"âœ… Vector store hazÄ±r")

    def create_collection(self, reset=False):
        """Collection oluÅŸtur veya yÃ¼kle"""

        if reset:
            try:
                self.client.delete_collection(self.collection_name)
                print("ğŸ—‘ï¸  Eski collection silindi")
            except:
                pass

        self.collection = self.client.get_or_create_collection(
            name=self.collection_name,
            metadata={"hnsw:space": "cosine"},  # Cosine similarity kullan
        )

        print(
            f"ğŸ“š Collection: {self.collection_name} (DÃ¶kÃ¼man sayÄ±sÄ±: {self.collection.count()})"
        )

    def add_documents(self, documents: List[Dict], batch_size=100):
        """
        DÃ¶kÃ¼manlarÄ± vector DB'ye ekle

        documents: [
            {
                'id': 'migren',
                'text': 'Migren baÅŸ aÄŸrÄ±sÄ±...',
                'metadata': {'bolum': 'NÃ¶roloji', ...}
            },
            ...
        ]
        """

        print(f"\nğŸ“¥ {len(documents)} dÃ¶kÃ¼man ekleniyor...")

        # Batch'lerle ekle (bellek tasarrufu)
        for i in range(0, len(documents), batch_size):
            batch = documents[i : i + batch_size]

            # Embedding'leri hesapla
            texts = [doc["text"] for doc in batch]
            embeddings = self.embedder.encode_batch(texts, show_progress=False)

            # ChromaDB'ye ekle
            self.collection.add(
                ids=[doc["id"] for doc in batch],
                embeddings=embeddings.tolist(),
                documents=texts,
                metadatas=[doc["metadata"] for doc in batch],
            )

            print(f"  âœ“ {i+len(batch)}/{len(documents)} eklendi")

        print(f"âœ… TÃ¼m dÃ¶kÃ¼manlar eklendi!")
        print(f"ğŸ“Š Toplam: {self.collection.count()} dÃ¶kÃ¼man")

    def search(self, query: str, n_results=5, filter_bolum=None):
        """
        Sorguya en benzer dÃ¶kÃ¼manlarÄ± bul

        query: "BaÅŸÄ±m aÄŸrÄ±yor"
        n_results: KaÃ§ sonuÃ§ dÃ¶nsÃ¼n
        filter_bolum: Sadece belirli bÃ¶lÃ¼mden ara
        """

        # Sorguyu embedding'e Ã§eviriyor , sayÄ±sal olarak
        query_embedding = self.embedder.encode_text(query)

        # ChromaDB'de ara
        where_filter = None
        
        
        # eÄŸer veriler arasÄ±nda Ã¶zel bi arama yapÄ±lmasÄ± gerekiyorsa ona gÃ¶re ek sorgular da yapÄ±labilir
        if filter_bolum:
            where_filter = {"bolum": filter_bolum}

        # ÅŸu an sadece en alakalÄ± gelen ilk 3 tane sonuÃ§ Ã¼zerinden cevap Ã¼retiliyor
        # Bundan sonraki amaÃ§ bu sonuÃ§larÄ±n ilk 10 tanesi ilk olarak toplandÄ±ktan sonra 
        # bu 10 tanesinin tekrar filtrelenmesi ile en iyi ÅŸekilde sonuÃ§larÄ±n Ã¼retilmesi saÄŸlanacak
        results = self.collection.query(
            query_embeddings=[query_embedding.tolist()],
            n_results=n_results,
            where=where_filter,
        )

        # SonuÃ§larÄ± formatla
        formatted_results = []

        for i in range(len(results["ids"][0])):
            formatted_results.append(
                {
                    "id": results["ids"][0][i],
                    "text": results["documents"][0][i],
                    "metadata": results["metadatas"][0][i],
                    "distance": results["distances"][0][i],
                    "similarity": 1
                    - results["distances"][0][i],  # Cosine'dan similarity'ye Ã§evir
                }
            )

        

        return formatted_results

    def get_collection_stats(self):
        """Database istatistikleri"""

        count = self.collection.count()

        # Ä°lk 100 dÃ¶kÃ¼mandan bÃ¶lÃ¼m daÄŸÄ±lÄ±mÄ±nÄ± al
        sample = self.collection.get(limit=min(100, count))

        bolumler = {}
        for metadata in sample["metadatas"]:
            bolum = str(metadata.get("bolum", "")).strip()
            bolumler[bolum] = bolumler.get(bolum, 0) + 1

        print(f"\nğŸ“Š Vector Database Ä°statistikleri:")
        print(f"   - Toplam dÃ¶kÃ¼man: {count}")
        print(f"   - BÃ¶lÃ¼m Ã§eÅŸitliliÄŸi: {len(bolumler)}")
        print(f"\n   Ã–rnek bÃ¶lÃ¼mler:")
        for bolum, cnt in list(bolumler.items())[:5]:
            print(f"     â€¢ {bolum}: {cnt}")


def build_vector_database():
    """Ana fonksiyon: Veriyi yÃ¼kle ve vector DB oluÅŸtur"""

    print("ğŸš€ VECTOR DATABASE OLUÅTURULUYOR")

    # 1. Ä°ÅŸlenmiÅŸ veriyi yÃ¼kle
    processed_data_path = Path("data/processed/diseases_processed.json")

    if not processed_data_path.exists():
        print(f"âŒ Ä°ÅŸlenmiÅŸ veri bulunamadÄ±: {processed_data_path}")
        print("Ã–nce data_loader.py'yi Ã§alÄ±ÅŸtÄ±r!")
        return

    with open(processed_data_path, "r", encoding="utf-8") as f:
        documents = json.load(f)

    print(f"âœ… {len(documents)} dÃ¶kÃ¼man yÃ¼klendi")

    # 2. Vector store oluÅŸtur
    vector_store = HealthVectorStore()
    vector_store.create_collection(reset=True)  # SÄ±fÄ±rdan baÅŸlasÄ±n 

    # 3. DÃ¶kÃ¼manlarÄ± ekle
    vector_store.add_documents(documents)

    # 4. Ä°statistikleri gÃ¶ster
    vector_store.get_collection_stats()

    # 5. Test aramasÄ±
    test_queries = ["BaÅŸÄ±m Ã§ok aÄŸrÄ±yor", "GÃ¶ÄŸsÃ¼mde aÄŸrÄ± var", "SaÃ§larÄ±m dÃ¶kÃ¼lÃ¼yor"]

    for query in test_queries:
        print(f"\nğŸ” Arama: '{query}'")
        results = vector_store.search(query, n_results=3)

        for i, result in enumerate(results, 1):
            print(
                f"\n  {i}. {result['metadata']['hastalik']} "
                f"(Benzerlik: {result['similarity']:.3f})"
            )
            print(f"     BÃ¶lÃ¼m: {result['metadata']['bolum']}")
            print(f"     Metin: {result['text'][:100]}...")

    print("\n" + "=" * 80)
    print("âœ… VECTOR DATABASE HAZIR!")
    print("=" * 80)


if __name__ == "__main__":
    build_vector_database()
