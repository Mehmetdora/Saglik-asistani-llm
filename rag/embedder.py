from sentence_transformers import SentenceTransformer
import numpy as np
from typing import List
import torch


class TurkishEmbedder:
    
    """
        Bu custom embedder class ile sorulan soru istenilen cevaplarÄ±n ne olacaÄŸÄ± 
        eÅŸleÅŸtiriliyor. Yani soruyu sayÄ±sal formata Ã§evirip hangi cevaba en yakÄ±n olacaÄŸÄ±
        bulunmak iÃ§in cosine karÅŸÄ±laÅŸtÄ±rmasÄ± yapÄ±lÄ±yor. 
    
        AmaÃ§ ise;
        - Soruyu embedding e Ã§evirmek 
        - Soru embedding i Ã¼zerinden en alakalÄ± hastalÄ±klarÄ± seÃ§mek
        
        yani sorulan soruya cevap vermek iÃ§in gerekli olan bilgilerin bulunmasÄ± kÄ±smÄ± burada yapÄ±lÄ±yor. 
    
        * Burada embedding boyutu her cÃ¼mlenin ne kadar detaylÄ± bir ÅŸekilde sayÄ±sal
        olarak temsil edildiÄŸidir. 
        metin â†’ [0.12, -0.34, 0.91, ..., 0.07]  (Ã¶r: 384 boyut)

        Az olmasÄ± hÄ±z ve ram olarak avantaj saÄŸlar,
        ama fazla olursa daha doÄŸru anlam karÅŸÄ±laÅŸtÄ±rmasÄ± yapÄ±labilir. Ã‡ok daha tutarlÄ± olur. 
        Fakat daha yavaÅŸ Ã§alÄ±ÅŸÄ±r, ram e baÄŸlÄ± olarak. 
        
        EÄŸer embedding modeli zayÄ±fsa , boyutu arttÄ±rmak kaliteyi arttÄ±rmaz,
        EÄŸer veri seti kÃ¼Ã§Ã¼kse , bÃ¼yÃ¼k embedding gereksiz olur. 
        
        - Embedding modeli sabit bir boyutta hazÄ±rlanmÄ±ÅŸtÄ±r. Bunu sonradan kod iÃ§inde 
        dÃ¼zenlenemez. Ä°lk baÅŸta proje iÃ§in embedding seÃ§imi yapÄ±lÄ±rken istenen embedding 
        boyutuna gÃ¶re model seÃ§imi yapÄ±lmalÄ±dÄ±r. 
        Yani embedding i 385 olan bir modeli hadi 760 yapayÄ±m diyemezsin. 
    
    """
    
    
    

    def __init__(
        self, model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2", device: str = None
    ):
        print(f"ðŸ§  Embedding modeli yÃ¼kleniyor: {model_name}")

        try:
            
            if torch.backends.mps.is_available():
                device = "mps"
                # apple iÃ§in 
            elif torch.cuda.is_available():
                device = "cuda" # NVIDIA GPU varsa (Windows/Linux)
            else:
                device = "cpu"
    
            self.model = SentenceTransformer(model_name,device=device)
            print(f"âœ… Model yÃ¼klendi")
            print("Model hakkÄ±nda detaylÄ± bilgiler: " , self.model._first_module().auto_model.config)

            # Embedding boyutunu test et
            test_embedding = self.model.encode("test")
            print(f"ðŸ“ Embedding boyutu: {len(test_embedding)}")

        except Exception as e:
            print(f"âŒ Model yÃ¼kleme hatasÄ±: {e}")
            print("ðŸ“¥ Ä°lk kullanÄ±mda model indirilecek, 5-10 dakika sÃ¼rebilir")
            raise

    #Tek bir metni embedding'e Ã§evir
    def encode_text(self, text: str) -> np.ndarray:
        return self.model.encode(text, convert_to_numpy=True)

    # birden fazla text i embedding yapmak iÃ§in 
    def encode_batch(
        self, texts: List[str], batch_size=32, show_progress=True
    ) -> np.ndarray:

        print(f"ðŸ”„ {len(texts)} metin encode ediliyor...")

        embeddings = self.model.encode(
            texts,
            batch_size=batch_size,
            show_progress_bar=show_progress,
            convert_to_numpy=True,
        )

        print(f"âœ… Encoding tamamlandÄ±: {embeddings.shape}")
        return embeddings

    # 2 metin arasÄ±ndaki cosine benzerliÄŸini bulmak iÃ§in 
    def similarity(self, text1: str, text2: str) -> float:
        """Ä°ki metin arasÄ±ndaki benzerlik (0-1)"""

        emb1 = self.encode_text(text1)
        emb2 = self.encode_text(text2)

        # Cosine similarity
        similarity = np.dot(emb1, emb2) / (np.linalg.norm(emb1) * np.linalg.norm(emb2))
        return float(similarity)


# Test
if __name__ == "__main__":
    embedder = TurkishEmbedder()

    # Benzerlik testi
    text1 = "BaÅŸÄ±m Ã§ok aÄŸrÄ±yor"
    text2 = "Migren hastasÄ±yÄ±m"
    text3 = "Dizim ÅŸiÅŸti"

    sim1 = embedder.similarity(text1, text2)
    sim2 = embedder.similarity(text1, text3)

    print(f"\nðŸ§ª Benzerlik Testi:")
    print(f"   '{text1}' vs '{text2}': {sim1:.3f}")
    print(f"   '{text1}' vs '{text3}': {sim2:.3f}")
    print(f"\n   âœ… Ä°lki daha benzer olmalÄ±: {sim1 > sim2}")
